#Linear Algebra
import numpy as np
#Data preprocessing
import pandas as pd
import seaborn as sns

# function to split the data for cross-validation
from sklearn.model_selection import train_test_split

#Selecting features
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import AdaBoostRegressor
from sklearn.datasets import load_boston

# Importing models
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import SGDClassifier
from lightgbm import LGBMClassifier
from xgboost  import XGBClassifier

# function for encoding categories
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics  import f1_score,accuracy_score
from sklearn.metrics import  confusion_matrix

# To help compare the algorithms
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report


mal_data = pd.read_csv("C:/Users/admin/Downloads/data.csv",sep = "|")


mal_data=mal_data.drop(["Name","md5"],axis=1)
X= mal_data.drop("legitimate",axis=1).values
y = mal_data["legitimate"].values

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

estimator = AdaBoostRegressor(random_state=0, n_estimators=50)
selector = SelectFromModel(estimator)
selector = selector.fit(X_train, y_train) 
status = selector.get_support()
print(selector.get_support())

selector.transform(X_train)

xgb = XGBClassifier()
xgb.fit(X_train,y_train)
xgbpredict = xgb.predict(X_test)
xgbscore=xgb.score(X_test, y_test)*100